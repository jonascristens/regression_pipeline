{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T08:58:17.965934Z",
     "start_time": "2023-04-20T08:58:17.853725Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from modelling_pkg.config import *\n",
    "from modelling_pkg.mappings import *\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "# ORGANIZATION_ID = get_org_id('data')\n",
    "\n",
    "ORGANIZATIONS, ORGANIZATION_ID = get_organizations(DATADIR)\n",
    "\n",
    "ORG_ID_R = {v: k for k, v in ORGANIZATION_ID.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dual_orgs = ORGANIZATIONS[ORGANIZATIONS.dual_currency].copy()\n",
    "dual_org_country_names = list(dual_orgs.index)\n",
    "print(dual_org_country_names)\n",
    "# display(dual_orgs)\n",
    "ctr2ex_rate_dom2int = dual_orgs.ex_rate_dom2int\n",
    "ctr2ex_rate_dom2int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "countries_dir = DATADIR + \"/countries\"\n",
    "\n",
    "Path(countries_dir).mkdir(parents=True, exist_ok=True)\n",
    "print(countries_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "offer_, audit_, oppo_, customer_, shipment_ = {}, {}, {}, {}, {}\n",
    "for i, org_id in enumerate(ORG_ID_R.keys()):\n",
    "    print(i, org_id)\n",
    "    offer_[org_id] = pd.read_csv(\n",
    "        f\"{DATADIR}/raw_tables/OFFERS/{org_id}.csv\",\n",
    "        parse_dates=[\n",
    "            \"creation_date\",\n",
    "            \"updated_date\",\n",
    "            \"offer_expiry_date\",\n",
    "            \"effective_start_date\",\n",
    "            \"agreement_renewal_date\",\n",
    "        ],\n",
    "    )\n",
    "    audit_[org_id] = pd.read_csv(\n",
    "        f\"{DATADIR}/raw_tables/OFFER_AUDIT/{org_id}.csv\",\n",
    "        parse_dates=[\"created_date\", \"updated_date\"],\n",
    "    )\n",
    "    oppo_[org_id] = pd.read_csv(\n",
    "        f\"{DATADIR}/raw_tables/OPPORTUNITY/{org_id}.csv\",\n",
    "        parse_dates=[\n",
    "            \"created_date\",\n",
    "            \"actual_close_date\",\n",
    "            \"expected_close_date\",\n",
    "            \"pipeline_last_updated_date\",\n",
    "        ],\n",
    "    )\n",
    "    customer_[org_id] = pd.read_csv(\n",
    "        f\"{DATADIR}/raw_tables/CUSTOMER/{org_id}.csv\",\n",
    "        parse_dates=[\"created_date\", \"ftb_month\"],\n",
    "    )\n",
    "    shipment_[org_id] = pd.read_csv(\n",
    "        f\"{DATADIR}/raw_tables/SHIPMENT_PROFILE/{org_id}.csv\",\n",
    "        parse_dates=[\"created_date\", \"last_updated_date\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "counts = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    offer_[\"DHL Italy\"].creation_date.min().date(),\n",
    "    offer_[\"DHL Italy\"].creation_date.max().date(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ctrs = sorted([ORG_ID_R[ctr_id] for ctr_id in offer_.organization_id.unique() if ctr_id in ORG_ID_R])\n",
    "# ctrs = ['COLUMBIA']\n",
    "# print(ctrs)\n",
    "# ctrs = [ctr for ctr in ['South_Africa', 'Nigeria', 'Mexico', 'Canada', 'United_States', 'Kenya'] if ctr in ctrs]\n",
    "# ctrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # onb = ['Indonesia', 'Bangladesh', 'Sri_Lanka', 'Hong_Kong', 'Japan']\n",
    "# onb = ['SRI_LANKA']\n",
    "# # country_codes = {\n",
    "# #     \"ID\": \"Indonesia\",\n",
    "# #     \"BD\": \"Bangladesh\",\n",
    "# #     \"LK\": \"Sri_Lanka\",\n",
    "# #     \"HK\": \"Hong_Kong\",\n",
    "# #     \"JP\": \"Japan\"\n",
    "# # }\n",
    "# # country_codes.values()\n",
    "\n",
    "# for c in onb:\n",
    "#     if c in ORGANIZATION_ID:\n",
    "#         print(c, '-', ORGANIZATION_ID[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for ctr_id in tqdm(ORG_ID_R.keys()):\n",
    "    # ctr_id = ORGANIZATION_ID[ctr]\n",
    "    ctr = ORG_ID_R[ctr_id]\n",
    "\n",
    "    ## Offers\n",
    "\n",
    "    offer = offer_[ctr_id].copy()\n",
    "\n",
    "    offer.rename(columns={\"creation_date\": \"created_date\"}, inplace=True)\n",
    "    offer.columns = offer.columns.str.lower()\n",
    "    offer = offer.drop(\n",
    "        columns=[\n",
    "            \"customer_id\",\n",
    "            \"offer_row_id\",\n",
    "            \"aag_id\",\n",
    "            \"cpa_id\",\n",
    "            \"composite_id\",\n",
    "            \"bpm_integration_id\",\n",
    "        ]\n",
    "    ).drop_duplicates()\n",
    "\n",
    "    offer = offer.add_suffix(\"_off\").rename(\n",
    "        columns={\n",
    "            \"organization_id_off\": \"organization_id\",\n",
    "            \"offer_id_off\": \"offer_id\",\n",
    "            \"gsfa_customer_id_off\": \"gsfa_customer_id\",\n",
    "            \"opportunity_id_off\": \"opportunity_id\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "    offer[\"time_taken\"] = (\n",
    "        offer.updated_date_off - offer.created_date_off\n",
    "    ) / np.timedelta64(1, \"D\")\n",
    "\n",
    "    ## Audit\n",
    "\n",
    "    audit = audit_[ctr_id].copy()\n",
    "\n",
    "    audit.columns = audit.columns.str.lower()\n",
    "    audit.drop(columns=[\"contactrole\"], inplace=True)\n",
    "    audit.drop_duplicates(inplace=True)\n",
    "\n",
    "    # sorting by updated date\n",
    "    audit.sort_values(\n",
    "        [\"organization_id\", \"offer_id\", \"updated_date\", \"new_value\"], inplace=True\n",
    "    )\n",
    "\n",
    "    ## Outcomes\n",
    "\n",
    "    # outcome from AUDIT - final record in GROUP BY of date-sorted status updates\n",
    "    outcome = audit.groupby(\"offer_id\").last().reset_index()\n",
    "    outcome = outcome.merge(\n",
    "        audit.groupby(\"offer_id\")\n",
    "        .new_value.value_counts()\n",
    "        .unstack()[\"Offer with Customer\"]\n",
    "        .rename(\"sent_out\"),\n",
    "        how=\"left\",\n",
    "        on=\"offer_id\",\n",
    "    )\n",
    "\n",
    "    # default status\n",
    "    outcome[\"outcome\"] = \"In Progress\"\n",
    "    # Accepted offers\n",
    "    outcome.loc[outcome.new_value == \"Agreement Created\", \"outcome\"] = \"Accepted\"\n",
    "    # Rejected offers\n",
    "    outcome.loc[outcome.new_value == \"Customer Rejected\", \"outcome\"] = \"Rejected\"\n",
    "    # Invalidated internally\n",
    "    outcome.loc[outcome.new_value == \"Invalidated\", \"outcome\"] = \"Invalidated DHL\"\n",
    "    # Invalidated after offering to customer\n",
    "    outcome.loc[\n",
    "        (outcome.new_value == \"Invalidated\")\n",
    "        & (outcome.old_value == \"Customer Rejected\"),\n",
    "        \"outcome\",\n",
    "    ] = \"Rejected\"\n",
    "    outcome.loc[\n",
    "        (outcome.new_value == \"Invalidated\")\n",
    "        & (outcome.old_value == \"Customer Accepted\"),\n",
    "        \"outcome\",\n",
    "    ] = \"Rejected\"\n",
    "    outcome.loc[\n",
    "        (outcome.new_value == \"Invalidated\")\n",
    "        & (outcome.old_value == \"Offer with Customer\"),\n",
    "        \"outcome\",\n",
    "    ] = \"Rejected\"\n",
    "\n",
    "    outcome = outcome[outcome.sent_out.notna()]\n",
    "    outcome.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    ## Opportunity\n",
    "\n",
    "    oppo = oppo_[ctr_id].copy()\n",
    "\n",
    "    oppo.columns = oppo.columns.str.lower()\n",
    "    oppo.drop_duplicates(inplace=True)\n",
    "    oppo = oppo.add_suffix(\"_oppo\").rename(\n",
    "        columns={\n",
    "            \"organization_id_oppo\": \"organization_id\",\n",
    "            \"opportunity_id_oppo\": \"opportunity_id\",\n",
    "            \"gsfa_customer_id_oppo\": \"gsfa_customer_id\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "    ## Customer\n",
    "\n",
    "    customer = customer_[ctr_id].copy()\n",
    "\n",
    "    customer.drop_duplicates(inplace=True)\n",
    "    customer.columns = customer.columns.str.lower()\n",
    "    customer = customer.add_suffix(\"_cust\").rename(\n",
    "        columns={\n",
    "            \"organization_id_cust\": \"organization_id\",\n",
    "            \"gsfa_customer_id_cust\": \"gsfa_customer_id\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "    ## Shipments\n",
    "\n",
    "    shipment = shipment_[ctr_id].copy()\n",
    "\n",
    "    shipment.columns = shipment.columns.str.lower()\n",
    "    shipment.rename(columns={\"last_updated_date\": \"updated_date\"}, inplace=True)\n",
    "    shipment.published_revenue.replace(0, np.nan, inplace=True)\n",
    "    shipment[\"discount\"] = (\n",
    "        100.0 - 100.0 * shipment.expected_revenue / shipment.published_revenue\n",
    "    )\n",
    "    shipment.sort_values(\n",
    "        [\"organization_id\", \"offer_id\", \"product_cluster\"], inplace=True\n",
    "    )\n",
    "    shipment.drop_duplicates()\n",
    "    shipment = shipment.add_suffix(\"_shp\").rename(\n",
    "        columns={\n",
    "            \"organization_id_shp\": \"organization_id\",\n",
    "            \"offer_id_shp\": \"offer_id\",\n",
    "            \"gsfa_customer_id_shp\": \"gsfa_customer_id\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Merging\n",
    "\n",
    "    # start from SHIPMENT (as a basis for product-level prediction)\n",
    "    step1 = shipment.merge(\n",
    "        offer, how=\"left\", on=[\"organization_id\", \"offer_id\", \"gsfa_customer_id\"]\n",
    "    )\n",
    "\n",
    "    step2 = step1.merge(\n",
    "        oppo, how=\"left\", on=[\"organization_id\", \"opportunity_id\", \"gsfa_customer_id\"]\n",
    "    )\n",
    "\n",
    "    step3 = step2.merge(\n",
    "        customer.drop(columns=[\"customer_name_cust\"]),\n",
    "        how=\"left\",\n",
    "        on=[\"organization_id\", \"gsfa_customer_id\"],\n",
    "    )\n",
    "    step4 = step3.merge(\n",
    "        outcome[[\"offer_id\", \"outcome\", \"sent_out\", \"new_value\", \"old_value\"]],\n",
    "        how=\"left\",\n",
    "        on=\"offer_id\",\n",
    "    )\n",
    "\n",
    "    # Initial filtering & enrichment\n",
    "\n",
    "    # merge into final dataset\n",
    "    final = step4[\n",
    "        (step4.sent_out.notna()) & (step4.outcome != \"Invalidated DHL\")\n",
    "    ].copy()\n",
    "    final.shape\n",
    "\n",
    "    # Define product domains - TDI, DDI and DOM\n",
    "    final[\"product_mix\"] = final.product_cluster_shp.map(\n",
    "        {\n",
    "            \"TDExport\": \"PROD.MIX:TDEXPORT\",\n",
    "            \"TDImport\": \"PROD.MIX:TDIMPORT\",\n",
    "            \"TD3rd\": \"PROD.MIX:TD3RD\",\n",
    "            \"DDExport\": \"PROD.MIX:DDEXPORT\",\n",
    "            \"DDImport\": \"PROD.MIX:DDIMPORT\",\n",
    "            \"DD3rd\": \"PROD.MIX:DD3RD\",\n",
    "            \"TDDom\": \"PROD.MIX:TDDOM\",\n",
    "            \"TD3rdDom\": \"PROD.MIX:TD3DOM\",\n",
    "        }\n",
    "    ).fillna(\"PROD.MIX:OTHER\")\n",
    "\n",
    "    # Define product domains - TDI, DDI and DOM\n",
    "    final[\"product_domain\"] = final.product_cluster_shp.map(\n",
    "        {\n",
    "            \"TDExport\": \"TDI\",\n",
    "            \"TDImport\": \"TDI\",\n",
    "            \"TD3rd\": \"TDI\",\n",
    "            \"TDDom\": \"DOM\",\n",
    "            \"TD3rdDom\": \"DOM\",\n",
    "            \"DDExport\": \"DDI\",\n",
    "            \"DDImport\": \"DDI\",\n",
    "            \"DD3rd\": \"DDI\",\n",
    "        }\n",
    "    ).fillna(\"OTHER\")\n",
    "\n",
    "    # integrity flags\n",
    "    final[\"empty_exp\"] = (final.expected_revenue_shp.isna()).astype(\"int\")\n",
    "    final[\"empty_pub\"] = (final.published_revenue_shp.isna()).astype(\"int\")\n",
    "    final[\"empty_any\"] = final.empty_exp | final.empty_pub\n",
    "    final[\"empty_all\"] = final.empty_exp & final.empty_pub\n",
    "\n",
    "    final[\"valid_discount\"] = (\n",
    "        (final.discount_shp >= 0) & (final.discount_shp <= 100)\n",
    "    ).astype(\"int\")\n",
    "\n",
    "    ## Keep only products (shipments) with valid discount\n",
    "\n",
    "    final = final[final.valid_discount == 1]\n",
    "\n",
    "    ## Currency adjustment for dual-currency countries (Domestic vs International)\n",
    "\n",
    "    if ctr in dual_org_country_names:\n",
    "        print(\"dual currency adjustment...\")\n",
    "        er = ctr2ex_rate_dom2int[ctr]\n",
    "        cond = final.product_domain == \"DOM\"\n",
    "        for col in [\n",
    "            \"published_revenue_shp\",\n",
    "            \"recommended_revenue_shp\",\n",
    "            \"expected_revenue_shp\",\n",
    "        ]:\n",
    "            final.loc[cond, col] = final[cond][col] / er\n",
    "        # cond = final.product_domain == 'TDI'\n",
    "        # final.loc[cond, 'recommended_revenue_shp'] = final[cond].recommended_revenue_shp / er\n",
    "\n",
    "    ## Offer-level revenues, discounts, and offer composition (by product cluster & domain)\n",
    "\n",
    "    final[\"offer_expected_revenue\"] = final.groupby(\n",
    "        \"offer_id\"\n",
    "    ).expected_revenue_shp.transform(\"sum\")\n",
    "    final[\"offer_published_revenue\"] = final.groupby(\n",
    "        \"offer_id\"\n",
    "    ).published_revenue_shp.transform(\"sum\")\n",
    "    final[\"offer_recommended_revenue\"] = final.groupby(\n",
    "        \"offer_id\"\n",
    "    ).recommended_revenue_shp.transform(\"sum\")\n",
    "\n",
    "    final[\"log_offer_published_revenue\"] = final.offer_published_revenue.apply(np.log)\n",
    "    final[\"offer_discount\"] = 100.0 * (\n",
    "        1.0 - final.offer_expected_revenue / final.offer_published_revenue\n",
    "    )\n",
    "    final[\"offer_products\"] = final.groupby(\"offer_id\").product_cluster_shp.transform(\n",
    "        \"nunique\"\n",
    "    )\n",
    "\n",
    "    # for each offer calcualte the breakdown into product domains (% of products in total products)\n",
    "    aaa = (\n",
    "        final.groupby([\"offer_id\", \"product_domain\"])\n",
    "        .published_revenue_shp.sum()\n",
    "        .unstack()\n",
    "    )\n",
    "    bbb = aaa.div(aaa.sum(axis=1), axis=0).reset_index().fillna(0)\n",
    "    bbb.rename(\n",
    "        columns={\n",
    "            \"TDI\": \"fraction_tdi\",\n",
    "            \"DDI\": \"fraction_ddi\",\n",
    "            \"DOM\": \"fraction_dom\",\n",
    "            \"OTHER\": \"fraction_other\",\n",
    "        },\n",
    "        inplace=True,\n",
    "    )\n",
    "    final = final.merge(bbb, on=\"offer_id\", how=\"left\")\n",
    "\n",
    "    # for each offer calcualte the breakdown into product mix (% of products in total products)\n",
    "    aaa = (\n",
    "        final.groupby([\"offer_id\", \"product_mix\"]).published_revenue_shp.sum().unstack()\n",
    "    )\n",
    "    bbb = aaa.div(aaa.sum(axis=1), axis=0).reset_index().fillna(0)\n",
    "    final = final.merge(bbb, on=\"offer_id\", how=\"left\")\n",
    "\n",
    "    ## Transformations & enrichments\n",
    "\n",
    "    # - Derive binary variables (e-commerce)\n",
    "    # - Add log-transformations on certain numeric variables\n",
    "    # - etc.\n",
    "\n",
    "    # - log transforms of weight variables\n",
    "    final.shipments_shp.replace(0, np.nan, inplace=True)\n",
    "    final.wps_shp.replace(0, np.nan, inplace=True)\n",
    "    final[\"weight\"] = final.shipments_shp * final.wps_shp\n",
    "\n",
    "    final[\"log_shipments\"] = final.shipments_shp.apply(np.log)\n",
    "    final[\"log_wps\"] = final.wps_shp.apply(np.log)\n",
    "    final[\"log_weight\"] = final.weight.apply(np.log)\n",
    "\n",
    "    final[\"log_discount\"] = final.discount_shp.apply(np.log)\n",
    "\n",
    "    final.published_revenue_shp.replace(0, np.nan, inplace=True)\n",
    "    final.new_potential_revenue_oppo.replace(0, np.nan, inplace=True)\n",
    "    final.opportunity_tpr_oppo.replace(0, np.nan, inplace=True)\n",
    "\n",
    "    final[\"log_published_revenue\"] = final.published_revenue_shp.apply(np.log)\n",
    "    final[\"log_published_revenue_sq\"] = (\n",
    "        final.log_published_revenue * final.log_published_revenue\n",
    "    )\n",
    "\n",
    "    final[\"log_potential_revenue\"] = (\n",
    "        final.new_potential_revenue_oppo.apply(np.log)\n",
    "        if final.new_potential_revenue_oppo.notna().sum() > 0\n",
    "        else np.nan\n",
    "    )\n",
    "    final[\"log_potential_revenue_tpr\"] = (\n",
    "        final.opportunity_tpr_oppo.apply(np.log)\n",
    "        if final.opportunity_tpr_oppo.notna().sum() > 0\n",
    "        else np.nan\n",
    "    )\n",
    "    diff_ = (\n",
    "        final[\"log_potential_revenue\"].fillna(-1)\n",
    "        != final[\"log_potential_revenue\"].fillna(-1)\n",
    "    ).sum()\n",
    "    print(f\"{diff_}/{len(final)} = {diff_ / len(final):.2f}\")\n",
    "\n",
    "    # E-commerce flag\n",
    "    final[\"ecomm\"] = 0\n",
    "    final.loc[final.physical_channel_cust.str.lower() == \"e-commerce\", \"ecomm\"] = 1\n",
    "\n",
    "    # Change added after ecom definition change\n",
    "    final.loc[final.physical_channel_cust.str.lower() == \"b2c e-commerce\", \"ecomm\"] = 1\n",
    "    final.loc[final.physical_channel_cust.str.lower() == \"b2b e-commerce\", \"ecomm\"] = 1\n",
    "\n",
    "    ## Mapped categoricals\n",
    "\n",
    "    # Pre-defined mapping\n",
    "\n",
    "    final[\"lead_oppo\"] = final.reason_for_lead_oppo.replace(LEAD_MAPPING)\n",
    "    final.loc[\n",
    "        final.lead_oppo.notna() & ~final.lead_oppo.isin(set(LEAD_MAPPING.values())),\n",
    "        \"lead_oppo\",\n",
    "    ] = \"LEAD:OTHER\"\n",
    "\n",
    "    final[\"lead_cust\"] = final.reason_for_lead_cust.replace(LEAD_MAPPING)\n",
    "    final.loc[\n",
    "        final.lead_cust.notna() & ~final.lead_cust.isin(set(LEAD_MAPPING.values())),\n",
    "        \"lead_cust\",\n",
    "    ] = \"LEAD:OTHER\"\n",
    "\n",
    "    final[\"initiator_oppo\"] = final.lead_source_type_oppo.replace(INITIATOR_MAPPING)\n",
    "    final.loc[\n",
    "        final.initiator_oppo.notna()\n",
    "        & ~final.initiator_oppo.isin(set(INITIATOR_MAPPING.values())),\n",
    "        \"initiator_oppo\",\n",
    "    ] = \"INIT:?\"\n",
    "\n",
    "    final[\"initiator_cust\"] = final.lead_source_type_cust.replace(INITIATOR_MAPPING)\n",
    "    final.loc[\n",
    "        final.initiator_cust.notna()\n",
    "        & ~final.initiator_cust.isin(set(INITIATOR_MAPPING.values())),\n",
    "        \"initiator_cust\",\n",
    "    ] = \"INIT:?\"\n",
    "\n",
    "    final[\"competitor_oppo\"] = final.primary_competitor_oppo.replace(COMPETITOR_MAPPING)\n",
    "    final.loc[\n",
    "        final.competitor_oppo.notna()\n",
    "        & ~final.competitor_oppo.isin(set(COMPETITOR_MAPPING.values())),\n",
    "        \"competitor_oppo\",\n",
    "    ] = \"COMP:OTHER\"\n",
    "\n",
    "    final[\"competitor_cust\"] = final.competitor_cust.replace(COMPETITOR_MAPPING)\n",
    "    final.loc[\n",
    "        final.competitor_cust.notna()\n",
    "        & ~final.competitor_cust.isin(set(COMPETITOR_MAPPING.values())),\n",
    "        \"competitor_cust\",\n",
    "    ] = \"COMP:OTHER\"\n",
    "\n",
    "    final[\"industry\"] = \"IND:\" + final.industry_code_cust.fillna(\"NODATA\").apply(\n",
    "        lambda x: x[:4]\n",
    "    )\n",
    "    final.industry.replace(\"IND:NODA\", np.nan, inplace=True)\n",
    "\n",
    "    # Final Filtering\n",
    "\n",
    "    ## Keep only offers without OTHER domain\n",
    "\n",
    "    # clusters - only include TDI, DDI and DOM\n",
    "    dataset = (\n",
    "        final[final.fraction_other == 0].copy()\n",
    "        if \"fraction_other\" in final.columns\n",
    "        else final.copy()\n",
    "    )\n",
    "\n",
    "    ## Remove offers with CustomPIDs and 100% discounts\n",
    "\n",
    "    # CustomPID with zero expected revenue\n",
    "    cpid_list = dataset[dataset.selected_pid_name_shp == \"CustomPID\"].offer_id.to_list()\n",
    "    dataset = dataset[\n",
    "        ~(dataset.offer_id.isin(cpid_list) & (dataset.expected_revenue_shp == 0))\n",
    "    ]\n",
    "\n",
    "    ## Establish order within an opportunity, and set the flag if the offer is final (within its OPPO)\n",
    "    # * order\n",
    "\n",
    "    # add order (X out of Y) on the clean set\n",
    "    order_in_oppo = (\n",
    "        dataset.groupby([\"opportunity_id\", \"offer_id\"])\n",
    "        .created_date_off.first()\n",
    "        .reset_index()\n",
    "        .sort_values(\"created_date_off\")\n",
    "    )\n",
    "    order_in_oppo[\"order_in_oppo\"] = (\n",
    "        order_in_oppo.groupby(\"opportunity_id\").cumcount() + 1\n",
    "    )\n",
    "\n",
    "    # calculate number of offers\n",
    "    no_of_offers = dataset.groupby(\"opportunity_id\").offer_id.nunique().reset_index()\n",
    "    no_of_offers.rename(columns={\"offer_id\": \"offers_in_oppo\"}, inplace=True)\n",
    "\n",
    "    dataset = dataset.merge(\n",
    "        order_in_oppo.drop(columns=\"created_date_off\"),\n",
    "        how=\"left\",\n",
    "        on=[\"offer_id\", \"opportunity_id\"],\n",
    "    )\n",
    "    dataset = dataset.merge(no_of_offers, how=\"left\", on=\"opportunity_id\")\n",
    "\n",
    "    # sequence and status helper fields\n",
    "    dataset[\"finality\"] = \"final\"\n",
    "    dataset.loc[dataset.offers_in_oppo != dataset.order_in_oppo, \"finality\"] = \"interim\"\n",
    "\n",
    "    # final status & discount\n",
    "    a = (\n",
    "        dataset.sort_values(\"created_date_off\")\n",
    "        .groupby([\"opportunity_id\", \"product_cluster_shp\"])[[\"outcome\", \"discount_shp\"]]\n",
    "        .last()\n",
    "        .reset_index()\n",
    "        .rename(\n",
    "            columns={\"outcome\": \"final_outcome\", \"discount_shp\": \"final_discount_shp\"}\n",
    "        )\n",
    "    )\n",
    "    a.head(3)\n",
    "\n",
    "    dataset = dataset.merge(a, how=\"left\", on=[\"opportunity_id\", \"product_cluster_shp\"])\n",
    "\n",
    "    ## Define revenue bins\n",
    "\n",
    "    # New approach\n",
    "    # Approved by Alex Goldirev to replace manual limits with data-guided limits.\n",
    "    # We discard top 5% of offers (by offer revenue)\n",
    "\n",
    "    labels = [\"low\", \"mid-low\", \"medium\", \"mid-high\", \"high\"]\n",
    "\n",
    "    dataset[\"revenue_bin\"] = np.nan\n",
    "\n",
    "    for country in dataset.organization_id.unique():\n",
    "        # offer revenues\n",
    "        offer_revenues = dataset[dataset.organization_id == country][\n",
    "            [\"offer_id\", \"offer_published_revenue\"]\n",
    "        ].drop_duplicates()\n",
    "\n",
    "        dataset.loc[dataset.organization_id == country, \"revenue_bin\"] = pd.cut(\n",
    "            dataset[dataset.organization_id == country].offer_published_revenue,\n",
    "            np.linspace(0, offer_revenues.offer_published_revenue.quantile(0.95), 6),\n",
    "            right=False,\n",
    "            labels=labels,\n",
    "            precision=3,\n",
    "            duplicates=\"drop\",\n",
    "        )\n",
    "\n",
    "    dataset[\"discount_oms\"] = (\n",
    "        100.0 - 100.0 * dataset.recommended_revenue_shp / dataset.published_revenue_shp\n",
    "    )\n",
    "    dataset[\"discount_delta\"] = dataset.discount_shp - dataset.discount_oms\n",
    "\n",
    "    # Save `dataset_short.csv`\n",
    "\n",
    "    dataset = dataset.reset_index(drop=True)\n",
    "    path_ = os.path.join(countries_dir, f\"{ctr}.csv\")\n",
    "    dataset.to_csv(path_, index=False)\n",
    "\n",
    "    print(f\"{ctr.ljust(20)} - {len(dataset):8,} | saved to: {path_}\")\n",
    "    counts[\"organization_id\"].append(ctr_id)\n",
    "    counts[\"country\"].append(ctr)\n",
    "    counts[\"n_offers\"].append(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for ctr in ORGANIZATION_ID:\n",
    "    final = pd.read_csv(f\"{countries_dir}/{ctr}.csv\", low_memory=False)\n",
    "    final = final[\n",
    "        final.log_potential_revenue.notna() | final.log_potential_revenue_tpr.notna()\n",
    "    ]\n",
    "    diff_ = (\n",
    "        final[\"log_potential_revenue\"].fillna(-1)\n",
    "        != final[\"log_potential_revenue_tpr\"].fillna(-1)\n",
    "    ).sum()\n",
    "    print(\n",
    "        f\"{ctr.ljust(26, '.')} {diff_:4}/{len(final):6} = {diff_ / len(final) * 100:.1f}%\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = []\n",
    "s = 0\n",
    "for ctr in ORGANIZATION_ID:\n",
    "    final = pd.read_csv(f\"{countries_dir}/{ctr}.csv\", low_memory=False)\n",
    "\n",
    "    final[\"physical_channel_cust2\"] = final.physical_channel_cust.map(\n",
    "        lambda x: x if x in [\"B2C E-Commerce\", \"B2B E-Commerce\"] else np.nan\n",
    "    )\n",
    "    final.physical_channel_cust = final.physical_channel_cust.fillna(\"~\")\n",
    "    final.physical_channel_cust2 = final.physical_channel_cust2.fillna(\"~\")\n",
    "\n",
    "    diff_ = (final[\"physical_channel_cust\"] != final[\"physical_channel_cust2\"]).sum()\n",
    "    print(\n",
    "        f\"{ctr.ljust(26, '.')} {diff_:4}/{len(final):6} = {diff_ / len(final) * 100:.1f}%\"\n",
    "    )\n",
    "    # display(final.industry.value_counts(dropna=False))\n",
    "    x = final.industry.fillna(\"nan\").value_counts()\n",
    "    s += x\n",
    "    a.append(final[[\"industry\"]])\n",
    "\n",
    "    # display(s)\n",
    "    # break\n",
    "# final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.concat(a)\n",
    "(df.value_counts(dropna=False) / len(df) * 100).round(1)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"industry_counts.csv\")\n",
    "df2.columns = [\"ind\", \"n\"]\n",
    "df2[\"n\"] = df2[\"n\"] / df2[\"n\"].sum() * 100\n",
    "df2.set_index(\"ind\").n.round(1).sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final[\"physical_channel_cust2\"] = final.physical_channel_cust.map(\n",
    "    lambda x: x if x in [\"B2C E-Commerce\", \"B2B E-Commerce\"] else np.nan\n",
    ")\n",
    "\n",
    "final.physical_channel_cust = final.physical_channel_cust.fillna(\"~\")\n",
    "final.physical_channel_cust2 = final.physical_channel_cust2.fillna(\"~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df = pd.read_excel(\"_data\\Countries_dataset_transformed.xlsx\")\n",
    "# df = pd.read_csv(\"_data\\Countries_dataset_transformed.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final = (\n",
    "    df[df.organization_id == ORGANIZATION_ID[\"AUSTRIA\"]]\n",
    "    .replace(\"?\", np.nan)\n",
    "    .replace(0, np.nan)\n",
    ")\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final0 = final.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final0[final0.product_domain != \"OTHER\"].groupby(\"product_domain\").head(4)[\n",
    "    [\n",
    "        \"product_domain\",\n",
    "        \"published_revenue_shp\",\n",
    "        \"recommended_revenue_shp\",\n",
    "        \"expected_revenue_shp\",\n",
    "    ]\n",
    "].sort_values(\"product_domain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if ctr in dual_org_country_names:\n",
    "    er = ctr2ex_rate_dom2int[ctr]\n",
    "    print(er)\n",
    "    cond = final.product_domain == \"DOM\"\n",
    "    for col in [\n",
    "        \"published_revenue_shp\",\n",
    "        \"recommended_revenue_shp\",\n",
    "        \"expected_revenue_shp\",\n",
    "    ]:\n",
    "        final.loc[cond, col] = final[cond][col] / er\n",
    "\n",
    "    cond = final.product_domain == \"TDI\"\n",
    "    final.loc[cond, \"recommended_revenue_shp\"] = (\n",
    "        final[cond].recommended_revenue_shp / er\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final[final.product_domain != \"OTHER\"].groupby(\"product_domain\").head(4)[\n",
    "    [\n",
    "        \"product_domain\",\n",
    "        \"published_revenue_shp\",\n",
    "        \"recommended_revenue_shp\",\n",
    "        \"expected_revenue_shp\",\n",
    "    ]\n",
    "].sort_values(\"product_domain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# (dataset.updated_date_shp < pd.to_datetime('2024-01-02')).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "counts_df = pd.DataFrame(counts).drop_duplicates()\n",
    "path_ = os.path.join(countries_dir, \"0_counts.csv\")\n",
    "counts_df.to_csv(path_, index=False)\n",
    "print(f\"saved to: {path_}\")\n",
    "display(counts_df.sort_values(\"n_offers\", ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "327.587px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": false,
  "vscode": {
   "interpreter": {
    "hash": "35ae2548ec875654b31682ef1f58c3ea7f0e9ebb8816f0d137ef9b5c82f45949"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
