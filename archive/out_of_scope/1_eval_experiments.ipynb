{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1fd8ff6",
   "metadata": {},
   "source": [
    "# ROM - Evaluate Experiments Automatically\n",
    "\n",
    "#### Description\n",
    "\n",
    "The purpose of this notebook is to evaluate ROM offline experiments. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578a294f-0df0-4d78-97be-38ef6448cfaf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25f6d3a3-5bc3-435e-8ade-57ca34ca8141",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3eb090af-2dc3-4c8e-962b-5c516a820260",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import sys\n",
    "import os\n",
    "import os.path as path\n",
    "\n",
    "sys.path.insert(0, path.dirname(os.getcwd()))\n",
    "from pathlib import Path\n",
    "from modelling_pkg.config import DATADIR\n",
    "from utils import *\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rom import ROMTrainerConfig\n",
    "import dataclasses\n",
    "from random import sample\n",
    "from collections import defaultdict\n",
    "import math\n",
    "from warnings import warn\n",
    "from IPython.display import display\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator, PercentFormatter\n",
    "import seaborn as sns\n",
    "from matplotlib.ticker import StrMethodFormatter\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    log_loss,\n",
    ")\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "sns.set_theme()\n",
    "\n",
    "DATADIR = \"../\" + DATADIR\n",
    "ROM_PLOT_DIR = \"plots\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6542df2f-d6d0-48fa-9a5f-4c6e4a60ccab",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "473e9469-6c50-48e0-a4f3-21e69954d079",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PREP\n",
    "\n",
    "res_path = f\"{DATADIR}/rom_results/\"\n",
    "discounts = \"real\", \"rom\", \"mdd\"\n",
    "discount_names = \"Real\", \"ROM\", \"MDD\"\n",
    "\n",
    "\n",
    "def raise_warning(s, score, cfgns=None):\n",
    "    global warning_score, warning_scores, cfg_names\n",
    "    warn(s)\n",
    "    mult = 1\n",
    "    if cfgns is not None:\n",
    "        if isinstance(cfgns, str):\n",
    "            cfgns = [cfgns]\n",
    "        for cfgn in cfgns:\n",
    "            if cfgn in warning_scores:\n",
    "                warning_scores[cfgn] += score\n",
    "        mult = len(cfgns)\n",
    "    score *= mult / len(cfg_names)\n",
    "    warning_score += score\n",
    "\n",
    "\n",
    "def get_markers(n_lines):\n",
    "    markers = []\n",
    "    i = 0\n",
    "    while n_lines > 0:\n",
    "        m = \"o^P*\"[i]\n",
    "        n = min(10, n_lines)\n",
    "        markers.extend([m] * n)\n",
    "        n_lines -= n\n",
    "        i += 1\n",
    "    return [\"\"] + markers + [\"d\"]\n",
    "\n",
    "\n",
    "def show_experiments_w_countries(name_pattern=None):\n",
    "    exp2ctrs = defaultdict(list)\n",
    "    all_exp = glob(f\"{DATADIR}/rom_results/*/*\")\n",
    "    all_exp_names = set(map(lambda p: p.split(\"\\\\\")[-1], all_exp))\n",
    "    for p in all_exp:\n",
    "        exp2ctrs[p.split(\"\\\\\")[-1]].append(tuple(p.split(\"\\\\\")[-2].split(\"~\")))\n",
    "    printmd(\"**On which countries was each experiment conducted:**\\n\")\n",
    "    for e in sorted(exp2ctrs.keys()):\n",
    "        if name_pattern is None or name_pattern in e:\n",
    "            printmd(f\"**{e}** - {list(map(lambda l: l[0], exp2ctrs[e]))}\")\n",
    "    return exp2ctrs\n",
    "\n",
    "\n",
    "def show_available_countries(preselected_exp, exp2ctrs):\n",
    "    ctr_paths_ = glob(f\"{res_path}/*\")\n",
    "    ctr_spans = []\n",
    "    ctr_paths = []\n",
    "\n",
    "    printmd(\"**Countries:**\\n\")\n",
    "    i = 0\n",
    "    for p in ctr_paths_:\n",
    "        ctr_span = ctr, *span = tuple(p.split(\"\\\\\")[-1].split(\"~\"))\n",
    "        if preselected_exp is None or ctr_span in exp2ctrs[preselected_exp]:\n",
    "            ctr_spans.append(ctr_span)\n",
    "            ctr_paths.append(p)\n",
    "            print(f\"{i:2}.  {ctr} - {span}\")\n",
    "            i += 1\n",
    "    return ctr_spans, ctr_paths\n",
    "\n",
    "\n",
    "def show_available_experiments(\n",
    "    country_selection, ctr_spans, ctr_paths, preselected_exp\n",
    "):\n",
    "    ctr_name, *span = ctr_spans[country_selection]\n",
    "\n",
    "    exp_paths = glob(f\"{ctr_paths[country_selection]}/*\")\n",
    "    exp_names = []\n",
    "\n",
    "    preselected_exp_idx = None\n",
    "\n",
    "    printmd(f\"Selected country: **{ctr_name}**, span: {span}\\n\\n**Experiments:**\\n\")\n",
    "    for i, p in enumerate(exp_paths):\n",
    "        pre = \"\"\n",
    "        exp_name = p.split(\"\\\\\")[-1]\n",
    "        if exp_name == preselected_exp:\n",
    "            preselected_exp_idx = i\n",
    "            pre = \"$$$ \"\n",
    "        cfgns = list(map(lambda p0: p0.split(\"\\\\\")[-1], glob(f\"{p}/*\")))\n",
    "        exp_names.append(exp_name)\n",
    "        print(f\"{pre}{i:2}.  {exp_name}\")  #  - {cfgns}')\n",
    "        for cfgn in cfgns:\n",
    "            print(f\"\\t- {cfgn}\")\n",
    "\n",
    "    return ctr_name, span, exp_paths, exp_names, preselected_exp_idx\n",
    "\n",
    "\n",
    "def show_available_configs(experiment_selection, preselected_exp_idx, exp_names):\n",
    "    if preselected_exp_idx is not None:\n",
    "        experiment_selection = preselected_exp_idx\n",
    "    exp_name = exp_names[experiment_selection]\n",
    "    printmd(f\"Selected experiment: **{exp_name}**\\n\\n**Configurations:**\\n\")\n",
    "    cfg_paths = glob(f\"{exp_paths[experiment_selection]}/*\")\n",
    "    cfg_names_all = []\n",
    "    for i, p in enumerate(cfg_paths):\n",
    "        cfg_name = p.split(\"\\\\\")[-1]\n",
    "        cfg_names_all.append(cfg_name)\n",
    "        print(f\"{i:2}.  {cfg_name}\")\n",
    "    return exp_name, cfg_paths, cfg_names_all\n",
    "\n",
    "\n",
    "def show_selected_configs(config_selection, cfg_names_all):\n",
    "    if config_selection:\n",
    "        cfg_names = [cfg_names_all[cs] for cs in config_selection]\n",
    "    else:\n",
    "        cfg_names = cfg_names_all.copy()\n",
    "        config_selection = list(range(len(cfg_names_all)))\n",
    "    cfg_hash = hash(tuple(cfg_names)) % 1000\n",
    "    printmd(f\"**Selected configurations (hash: {cfg_hash}):**\\n\")\n",
    "    for cfgn in cfg_names:\n",
    "        print(cfgn)\n",
    "\n",
    "    return cfg_names, cfg_hash, config_selection\n",
    "\n",
    "\n",
    "def load_data_and_prep_eval(config_selection, cfg_paths, n_cols=4, n_cols_wide=2):\n",
    "    global warning_score, warning_scores, cfg_names\n",
    "    warning_score = 0\n",
    "    warning_scores = {cfgn: 0 for cfgn in cfg_names}\n",
    "\n",
    "    clf_dfs = {}\n",
    "    rcm_dfs = {}\n",
    "    eval_dfs = {}\n",
    "    configs = {}\n",
    "    dicts = []\n",
    "\n",
    "    for cs in config_selection:\n",
    "        res_path_ = cfg_paths[cs]\n",
    "\n",
    "        # cfg = ROMTrainerConfig(**json.load(open(f'{res_path_}/cfg.json', 'r')))  #, experiment='xyz')\n",
    "        cfg = ROMTrainerConfig.from_json_file(\n",
    "            f\"{res_path_}/cfg.json\"\n",
    "        )  # , experiment='xyz')\n",
    "        name = cfg.name\n",
    "\n",
    "        df = pd.read_csv(f\"{res_path_}/clf.csv\", index_col=0)\n",
    "        clf_dfs[name] = df.reset_index() if df.index.name else df\n",
    "\n",
    "        df = pd.read_csv(f\"{res_path_}/rom.csv\", index_col=0)\n",
    "        rcm_dfs[name] = df.reset_index() if df.index.name else df\n",
    "\n",
    "        eval_dfs[name] = pkl.load(open(f\"{res_path_}/eval.pkl\", \"rb\"))\n",
    "        configs[name] = cfg\n",
    "        cfg_d = dataclasses.asdict(cfg)\n",
    "        dicts.append(cfg_d)\n",
    "\n",
    "    gammas = cfg.gammas\n",
    "    n_configs = len(config_selection)\n",
    "\n",
    "    df_name = f\"{ctr_name} - {span}\"\n",
    "    cfgs_df = pd.DataFrame(dicts).rename(columns={\"name\": df_name}).set_index(df_name).T\n",
    "\n",
    "    # highlight differences\n",
    "    var_cols = []\n",
    "    for c in cfgs_df.T.columns:\n",
    "        col = cfgs_df.T[c]\n",
    "        if isinstance(col[0], list):\n",
    "            col = col.apply(tuple)\n",
    "        if col.nunique() > 1:\n",
    "            var_cols.append(c)\n",
    "\n",
    "    def custom_style(row):\n",
    "        if row.name in var_cols:\n",
    "            return [\"background-color: pink\"] * len(row.values)\n",
    "        return [\"\"] * len(row.values)\n",
    "\n",
    "    display(cfgs_df.style.apply(custom_style, axis=1))\n",
    "\n",
    "    n_cols = min(n_cols, n_configs)\n",
    "    n_rows = math.ceil(n_configs / n_cols)\n",
    "    n_rows_wide = math.ceil(n_configs / n_cols_wide)\n",
    "    models = cfg_names\n",
    "    n_models = len(models)\n",
    "\n",
    "    n_samples = len(rcm_dfs[cfg_names[0]])\n",
    "    return (\n",
    "        clf_dfs,\n",
    "        rcm_dfs,\n",
    "        eval_dfs,\n",
    "        n_samples,\n",
    "        configs,\n",
    "        (n_cols, n_rows, n_cols_wide, n_rows_wide),\n",
    "        models,\n",
    "        n_models,\n",
    "        gammas,\n",
    "        n_configs,\n",
    "    )\n",
    "\n",
    "\n",
    "# EVAL\n",
    "\n",
    "\n",
    "def show_selected_evaluation(ctr_name, span, exp_name, cfg_names):\n",
    "    printmd(\n",
    "        f'<font size=\"+2\">**Selected evaluation:**</font>\\n\\nCountry: **{ctr_name}** ({span})\\n\\nExperiment: **{exp_name}**'\n",
    "    )  # \\n\\nConfigurations: **{cfg_names}**')\n",
    "    cfgns_md = \"\"\n",
    "    for cfgn in cfg_names:\n",
    "        cfgns_md += f\"\\n- **{cfgn}**\"\n",
    "    printmd(f\"Configurations:{cfgns_md}\")\n",
    "\n",
    "\n",
    "def plot_pred_dist_acc_vs_rej():\n",
    "    global ctr_name, exp_name, n_rows, n_cols, cfg_names, clf_dfs, rcm_dfs, eval_dfs\n",
    "\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(4 * n_cols, n_rows * 3.5))\n",
    "\n",
    "    plt.suptitle(\n",
    "        f\"{ctr_name} - exp: {exp_name} | Distribution of predicted probabilities for accepted vs rejected offers\"\n",
    "    )\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for cfgn, ax in zip(cfg_names, axes):\n",
    "        axes2 = clf_dfs[cfgn].groupby(\"accepted\").pred.plot(kind=\"kde\", ax=ax)\n",
    "        for ax in axes2:\n",
    "            ax.set_xlim(0, 1)\n",
    "            ax.set_ylim(0, None)\n",
    "            ax.set_title(f\"{cfgn}\")\n",
    "            ax.set_xlabel(\"Predicted probability of acceptance\")\n",
    "        plt.legend([\"Rejected\", \"Accepted\"])\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Remove empty subplots if the number of plots is less than the total subplots\n",
    "    if n_configs < n_rows * n_cols:\n",
    "        for j in range(n_configs, n_rows * n_cols):\n",
    "            fig.delaxes(axes[j])\n",
    "\n",
    "\n",
    "def calc_metrics():\n",
    "    global ctr_name, exp_name, n_rows, n_cols, cfg_names, clf_dfs, rcm_dfs, eval_dfs\n",
    "    metrics_array = []\n",
    "    for cfgn in cfg_names:\n",
    "        clf_res = clf_dfs[cfgn]\n",
    "        metrics = dict(\n",
    "            acceptance_rate=clf_res.accepted.mean(),\n",
    "            accuracy=accuracy_score(clf_res[\"accepted\"], clf_res[\"pred_b\"]),\n",
    "            precision=precision_score(clf_res[\"accepted\"], clf_res[\"pred_b\"]),\n",
    "            recall=recall_score(clf_res[\"accepted\"], clf_res[\"pred_b\"]),\n",
    "            f1=f1_score(clf_res[\"accepted\"], clf_res[\"pred_b\"]),\n",
    "            auc_roc=roc_auc_score(clf_res[\"accepted\"], clf_res[\"pred\"]),\n",
    "            avg_precision=average_precision_score(clf_res[\"accepted\"], clf_res[\"pred\"]),\n",
    "            logloss=log_loss(clf_res[\"accepted\"], clf_res[\"pred\"]),\n",
    "        )\n",
    "        metrics_array.append(metrics)\n",
    "\n",
    "    return pd.DataFrame(metrics_array, index=cfg_names)\n",
    "\n",
    "\n",
    "def plot_metrics(df):\n",
    "    global n_configs\n",
    "    ax = df.T.plot()\n",
    "    colors_ = [l.get_c() for l in ax.get_lines()]\n",
    "    ax.remove()\n",
    "\n",
    "    n_rows_ = 2\n",
    "    n_cols_ = 2\n",
    "    fig, axes = plt.subplots(\n",
    "        n_rows_, n_cols_, figsize=(n_cols_ * n_configs * 0.8, n_rows_ * 4)\n",
    "    )\n",
    "\n",
    "    plt.suptitle(f\"{ctr_name} - exp: {exp_name} | Metrics\")\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for col, ax in zip([\"accuracy\", \"f1\", \"auc_roc\", \"logloss\"], axes):\n",
    "        ax = df[col].plot.bar(color=colors_, rot=25, ax=ax)\n",
    "\n",
    "        # ax.set_xlabel('False Positive Rate (FPR)')\n",
    "        # ax.set_ylabel('True Positive Rate (TPR)')\n",
    "        ax.set_title(col)\n",
    "        ax.set_ylabel(col)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    pass\n",
    "\n",
    "\n",
    "def plot_roc():\n",
    "    global n_rows, n_cols, ctr_name, exp_name, cfg_names, clf_dfs, rcm_dfs, eval_dfs\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(4 * n_cols, n_rows * 4))\n",
    "\n",
    "    plt.suptitle(f\"{ctr_name} - exp: {exp_name} | ROC Curve\")\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for cfgn, ax in zip(cfg_names, axes):\n",
    "        clf_res = clf_dfs[cfgn]\n",
    "\n",
    "        fpr, tpr, thresholds = roc_curve(clf_res[\"accepted\"], clf_res[\"pred\"])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "\n",
    "        warn_roc_thresh = 0.55\n",
    "        if roc_auc < warn_roc_thresh:\n",
    "            raise_warning(f\"ROC < {warn_roc_thresh} for {cfgn}\", 1, cfgn)\n",
    "\n",
    "        ax.plot(fpr, tpr, color=\"blue\", lw=2, label=\"ROC curve (AUC = %0.2f)\" % roc_auc)\n",
    "        ax.plot(\n",
    "            [0, 1], [0, 1], color=\"gray\", lw=1, linestyle=\"--\"\n",
    "        )  # Diagonal line for random classifier\n",
    "        ax.set_xlabel(\"False Positive Rate (FPR)\")\n",
    "        ax.set_ylabel(\"True Positive Rate (TPR)\")\n",
    "        ax.set_title(f\"{cfgn}\")\n",
    "        ax.legend(loc=\"lower right\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Remove empty subplots if the number of plots is less than the total subplots\n",
    "    if n_configs < n_rows * n_cols:\n",
    "        for j in range(n_configs, n_rows * n_cols):\n",
    "            fig.delaxes(axes[j])\n",
    "\n",
    "\n",
    "def get_random_examples(n_examples):\n",
    "    global cfg_names, clf_dfs, rcm_dfs, eval_dfs\n",
    "    example_idxs = sample(range(len(eval_dfs[cfg_names[0]])), n_examples)\n",
    "    examples = []\n",
    "    for cfgn in cfg_names:\n",
    "        examples.append([eval_dfs[cfgn][i] for i in example_idxs])\n",
    "    return examples\n",
    "\n",
    "\n",
    "def plot_examples_probability(examples, gamma, suptitle, real_discount):\n",
    "    global n_rows, n_cols, ctr_name, exp_name, cfg_names, clf_dfs, rcm_dfs, eval_dfs\n",
    "    n_examples = len(examples[0])\n",
    "    fig, axes = plt.subplots(\n",
    "        n_examples, n_configs, figsize=(4 * n_configs, n_examples * 3)\n",
    "    )\n",
    "\n",
    "    if suptitle:\n",
    "        plt.suptitle(\n",
    "            f\"{ctr_name} - exp. {exp_name} - predicted probability of accepting vs discount\"\n",
    "        )\n",
    "\n",
    "    for j, (cfgn, dfs) in enumerate(zip(cfg_names, examples)):\n",
    "        for i, (di, df) in enumerate(dfs):\n",
    "            ax = axes[i, j]\n",
    "            ax.plot(\n",
    "                df[\"discount_shp\"],\n",
    "                df[\"rom_pa\"] * 100,\n",
    "                marker=\"o\",\n",
    "                linestyle=\"-\",\n",
    "                linewidth=1,\n",
    "                markersize=4,\n",
    "            )\n",
    "            ax.set_title(f\"{f'{cfgn} - ' if i == 0 else ''}Plot {i + 1}\")\n",
    "            ax.set_xlabel(\"discount\")\n",
    "            ax.set_ylabel(\"probability\")\n",
    "            ax.yaxis.set_major_formatter(PercentFormatter(decimals=0))\n",
    "            if gamma:\n",
    "                dmin, dmax, dopt = di[gamma]\n",
    "                ax.axvspan(dmin, dmax, color=\"orange\", alpha=0.2)\n",
    "                ax.axvline(dopt, c=\"orange\", alpha=0.8, ls=\"--\")\n",
    "            if real_discount:\n",
    "                ax.axvline(df.real_discount.iloc[0], c=\"grey\", ls=\"--\")\n",
    "            ax.set_ylim(0, 100)\n",
    "            ax.set_xlim(0, 100)\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "def plot_examples_revenue(examples, gamma, suptitle, real_discount):\n",
    "    global n_rows, n_cols, ctr_name, exp_name, cfg_names, clf_dfs, rcm_dfs, eval_dfs\n",
    "\n",
    "    n_examples = len(examples[0])\n",
    "    fig, axes = plt.subplots(\n",
    "        n_examples, n_configs, figsize=(4 * n_configs, n_examples * 3)\n",
    "    )\n",
    "    if suptitle:\n",
    "        plt.suptitle(f\"{ctr_name} - exp. {exp_name} - expected revenue vs discount\")\n",
    "\n",
    "    for j, (cfgn, dfs) in enumerate(zip(cfg_names, examples)):\n",
    "        for i, (di, df) in enumerate(dfs):\n",
    "            ax = axes[i, j]\n",
    "            ax.plot(\n",
    "                df[\"discount_shp\"],\n",
    "                df[\"rom_exp_rev\"],\n",
    "                marker=\"o\",\n",
    "                linestyle=\"-\",\n",
    "                linewidth=1,\n",
    "                markersize=4,\n",
    "            )\n",
    "            ax.set_title(f\"{f'{cfgn} - ' if i == 0 else ''}Plot {i + 1}\")\n",
    "            ax.set_xlabel(\"discount\")\n",
    "            ax.set_ylabel(\"expected revenue\")\n",
    "            if gamma:\n",
    "                dmin, dmax, dopt = di[gamma]\n",
    "                ax.axvspan(dmin, dmax, color=\"orange\", alpha=0.2)\n",
    "                ax.axvline(dopt, c=\"orange\", alpha=0.8, ls=\"--\")\n",
    "            if real_discount:\n",
    "                ax.axvline(df.real_discount.iloc[0], c=\"grey\", ls=\"--\")\n",
    "            ax.yaxis.set_major_formatter(StrMethodFormatter(\"{x:,.0f}\"))\n",
    "            ax.set_xlim(0, 100)\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "def plot_interval_sizes():\n",
    "    #     todo\n",
    "    global n_rows, n_cols, ctr_name, exp_name, cfg_names, clf_dfs, rcm_dfs, eval_dfs\n",
    "    fig, axes = plt.subplots(\n",
    "        n_rows_wide,\n",
    "        n_cols_wide,\n",
    "        figsize=(10 * n_cols_wide, n_rows_wide * 4),\n",
    "        sharex=True,\n",
    "        sharey=True,\n",
    "    )\n",
    "\n",
    "    plt.suptitle(\n",
    "        f\"{ctr_name} - exp: {exp_name} | Sizes of recommended discount intervals\"\n",
    "    )\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for cfgn, ax in zip(cfg_names, axes):\n",
    "        rcm_res = rcm_dfs[cfgn]\n",
    "\n",
    "        rcm_res2 = rcm_res.copy()\n",
    "        for gamma in cfg.gammas:\n",
    "            rcm_res2[f\"Γ = {gamma}\"] = (\n",
    "                rcm_res2[f\"rom_discount_{gamma}_high\"]\n",
    "                - rcm_res2[f\"rom_discount_{gamma}_low\"]\n",
    "            )\n",
    "        rcm_res2 = rcm_res2[[f\"Γ = {gamma}\" for gamma in cfg.gammas]]\n",
    "        ax = rcm_res2.plot.kde(bw_method=0.25, ax=ax)\n",
    "        ax.set_xlim(-1, rcm_res2[f\"Γ = {gamma}\"].quantile(0.97))\n",
    "        ax.set_title(f\"{cfgn}\")\n",
    "        ax.set_xlabel(\"size of discount interval\")\n",
    "\n",
    "    # Remove empty subplots if the number of plots is less than the total subplots\n",
    "    if n_configs < n_rows_wide * n_cols_wide:\n",
    "        for j in range(n_configs, n_rows_wide * n_cols_wide):\n",
    "            fig.delaxes(axes[j])\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "def plot_discount_distributions():\n",
    "    global \\\n",
    "        n_rows_wide, \\\n",
    "        n_cols_wide, \\\n",
    "        ctr_name, \\\n",
    "        exp_name, \\\n",
    "        cfg_names, \\\n",
    "        clf_dfs, \\\n",
    "        rcm_dfs, \\\n",
    "        eval_dfs\n",
    "    fig, axes = plt.subplots(\n",
    "        n_rows_wide, n_cols_wide, figsize=(8 * n_cols_wide, n_rows_wide * 4)\n",
    "    )\n",
    "\n",
    "    plt.suptitle(f\"{ctr_name} - exp. {exp_name} - Distribution of discounts\")\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for cfgn, rcm_res, ax in zip(cfg_names, rcm_dfs.values(), axes):\n",
    "        cfgn_warned = False\n",
    "\n",
    "        n = len(rcm_res)\n",
    "        # check potential issues\n",
    "        real0 = (rcm_res.real_discount < 3).sum()\n",
    "        real0pct = real0 / n * 100\n",
    "        rec_opt0 = (rcm_res.rom_discount < 3).sum()\n",
    "        rec_opt0pct = rec_opt0 / n * 100\n",
    "        if rec_opt0 > 2 * real0 and rec_opt0pct > real0pct + 1.2:\n",
    "            raise_warning(\n",
    "                f\"0% discounts more frequently recommended than real discounts - {rec_opt0} vs {real0}/{len(rcm_res)} - {cfgn}\",\n",
    "                10,\n",
    "                cfgn,\n",
    "            )\n",
    "            cfgn_warned = True\n",
    "\n",
    "        # ax = rcm_res[['real_discount', 'rom_discount']].plot.kde(ax=ax, bw_method=0.25)\n",
    "        ax = rcm_res[[\"real_discount\", \"rom_discount\"]].plot.kde(\n",
    "            ax=ax, bw_method=0.25, color=[\"b\", \"r\"]\n",
    "        )\n",
    "        # ax = rcm_res[['real_discount', 'rom_discount', 'mdd_discount']].plot.kde(ax=ax, bw_method=0.25)\n",
    "        ax.set_xlim((0, 100))\n",
    "        ax.set_xlabel(\"Discount\")\n",
    "        # ax.legend(['Real', 'ROM', 'ROM - weighted intervals'])\n",
    "        ax.legend([f\"Real (zero-{real0pct:.1f}%)\", f\"ROM (zero-{rec_opt0pct:.1f}%)\"])\n",
    "\n",
    "        real_med = rcm_res.real_discount.median()\n",
    "        rom_med = rcm_res.rom_discount.median()\n",
    "        med_diff = round(abs(real_med - rom_med))\n",
    "        med_diff_thresh = 9\n",
    "        if med_diff > med_diff_thresh:\n",
    "            score = min((med_diff - 9) ** 2, 50)\n",
    "            raise_warning(\n",
    "                f\"medians of discounts differ too much! diff={med_diff} - {cfgn}\",\n",
    "                score,\n",
    "                cfgn,\n",
    "            )\n",
    "            ax.text(\n",
    "                16,\n",
    "                ax.get_ylim()[1] * 0.5,\n",
    "                \"median\",\n",
    "                fontsize=20,\n",
    "                weight=\"extra bold\",\n",
    "                color=\"b\",\n",
    "                horizontalalignment=\"left\",\n",
    "                verticalalignment=\"top\",\n",
    "            )\n",
    "        ax.axvline(real_med, color=ax.get_lines()[0].get_c(), alpha=0.5, ls=\"--\")\n",
    "        ax.axvline(rom_med, color=\"r\", alpha=0.5, ls=\"--\")\n",
    "\n",
    "        ax.set_title(f\"{cfgn} | med_diff={round(med_diff)}\")\n",
    "\n",
    "        if cfgn_warned:\n",
    "            ax.text(\n",
    "                10,\n",
    "                ax.get_ylim()[1] * 0.6,\n",
    "                \"0%\",\n",
    "                fontsize=20,\n",
    "                weight=\"extra bold\",\n",
    "                color=\"r\",\n",
    "                horizontalalignment=\"left\",\n",
    "                verticalalignment=\"top\",\n",
    "            )\n",
    "\n",
    "    if n_configs < n_rows_wide * n_cols_wide:\n",
    "        for j in range(n_configs, n_rows_wide * n_cols_wide):\n",
    "            fig.delaxes(axes[j])\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "# # How many real discounts within ROM\\'s recommended interval?\n",
    "# gamma = 8\n",
    "# within = []\n",
    "# for cfgn in cfg_names:\n",
    "#     res = rcm_dfs[cfgn]\n",
    "#     within0 = []\n",
    "#     within.append(within0)\n",
    "#     for gamma in gammas:\n",
    "#         w = len(res[(res.real_discount >= res[f'rom_discount_{gamma}_low'] - 0.2) & (res.real_discount <= res[f'rom_discount_{gamma}_high'] + 0.2)])\n",
    "#         within0.append(f'{round(100*w/len(res), 1)}%')\n",
    "# # print(f'Real discount is within ROM\\'s recommended interval in {w:.1f}% cases')\n",
    "# printmd('**How many real discounts within ROM\\'s recommended interval?**')\n",
    "# pd.DataFrame(within, columns=pd.Index(gammas, name='Γ'), index=cfg_names).T\n",
    "\n",
    "\n",
    "def plot_difference_between_discounts(show_means, means_alpha=0.3):\n",
    "    global \\\n",
    "        n_rows_wide, \\\n",
    "        n_cols_wide, \\\n",
    "        ctr_name, \\\n",
    "        exp_name, \\\n",
    "        cfg_names, \\\n",
    "        clf_dfs, \\\n",
    "        rcm_dfs, \\\n",
    "        eval_dfs, \\\n",
    "        models\n",
    "    fig, axes = plt.subplots(\n",
    "        n_rows_wide, n_cols_wide, figsize=(8 * n_cols_wide, n_rows_wide * 4)\n",
    "    )\n",
    "    plt.suptitle(\n",
    "        f\"{ctr_name} - Distribution of diff between recommended and actual discount\"\n",
    "    )\n",
    "    axes = axes.flatten()\n",
    "    m = \"rom\"\n",
    "    for cfgn, ax in zip(models, axes):\n",
    "        cfgn_warned = False\n",
    "        res = rcm_dfs[cfgn]\n",
    "\n",
    "        diff = res.groupby(\"accepted\")[f\"{m}_diff\"]\n",
    "        diff.plot(kind=\"kde\", ax=ax)\n",
    "        lim = max(\n",
    "            np.abs(res[f\"{m}_diff\"].quantile(0.001)),\n",
    "            np.abs(res[f\"{m}_diff\"].quantile(0.999)),\n",
    "        )\n",
    "        ax.set_xlim((-lim, lim))\n",
    "        ax.set_title(cfgn)\n",
    "        # ax.axvline(-EPS, c='grey', ls=':')\n",
    "        ax.axvline(0, c=\"black\", ls=\":\")\n",
    "        # ax.axvline(EPS, c='grey', ls=':')\n",
    "        ax.legend([\"Rejected\", \"Accepted\"])\n",
    "        ax.set_xlabel(\"Discount difference\")\n",
    "\n",
    "        diff_med = diff.median()\n",
    "        if show_means:\n",
    "            colors = [l.get_c() for l in ax.get_lines()]\n",
    "            ax.axvline(diff_med[1], color=colors[1], alpha=means_alpha, ls=\"--\")\n",
    "            ax.axvline(diff_med[0], color=colors[0], alpha=means_alpha, ls=\"--\")\n",
    "\n",
    "        # check potential issues\n",
    "        med0, med1 = diff_med.loc[0], diff_med.loc[1]\n",
    "        conds = (med0 < -5), (med1 > 5)\n",
    "        conds2 = (med0 > 19), (med1 < -13)\n",
    "        if sum(conds) or sum(conds2):\n",
    "            score = min(\n",
    "                100,\n",
    "                (\n",
    "                    ((abs(med0) - 4) ** 2 if conds[0] else 0)\n",
    "                    + ((abs(med1) - 4) ** 2 if conds[1] else 0)\n",
    "                )\n",
    "                * sum(conds),\n",
    "            )\n",
    "            if sum(conds2):\n",
    "                score += min(\n",
    "                    100,\n",
    "                    ((med0 - 19) ** 2 if conds2[0] else 0)\n",
    "                    + ((abs(med1) - 13) ** 2 if conds2[1] else 0),\n",
    "                )\n",
    "            raise_warning(\n",
    "                f\"(+{score:5.1f}) - {cfgn} - Unexpected median value\", score, cfgn\n",
    "            )\n",
    "            ax.text(\n",
    "                ax.get_xlim()[0] * 0.8,\n",
    "                ax.get_ylim()[1] * 0.6,\n",
    "                f\"median{'s' if sum(conds) == 2 else ''} (+{score:.1f})\",\n",
    "                fontsize=20,\n",
    "                weight=\"extra bold\",\n",
    "                color=\"b\",\n",
    "                horizontalalignment=\"left\",\n",
    "                verticalalignment=\"top\",\n",
    "            )\n",
    "\n",
    "        large_diff_thresh = 40\n",
    "        large_diff_pct = (res[f\"{m}_diff\"] < -large_diff_thresh).sum() / len(res) * 100\n",
    "        if large_diff_pct > 3:\n",
    "            score = 10\n",
    "            if m == \"rom\":\n",
    "                raise_warning(\n",
    "                    f\"{cfgn} - Much smaller recommended discounts than real discounts (diff>{large_diff_thresh}) are frequent ({large_diff_pct:.2f}%)\",\n",
    "                    score,\n",
    "                    cfgn,\n",
    "                )\n",
    "            ax.text(\n",
    "                ax.get_xlim()[0] * 0.8,\n",
    "                ax.get_ylim()[1] * 0.7,\n",
    "                f\"small (+{score})\",\n",
    "                fontsize=20,\n",
    "                weight=\"extra bold\",\n",
    "                color=\"r\",\n",
    "                horizontalalignment=\"left\",\n",
    "                verticalalignment=\"top\",\n",
    "            )\n",
    "\n",
    "    if n_models < n_rows_wide * n_cols_wide:\n",
    "        for j in range(n_models, n_rows_wide * n_cols_wide):\n",
    "            fig.delaxes(axes[j])\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "# RCR\n",
    "\n",
    "# def calc_rcr_dfs():\n",
    "#     global cfg_names, clf_dfs, rcm_dfs, eval_dfs, MDD_EPSS\n",
    "#     MDD_EPSS = [x//2 for x in gammas]\n",
    "#     assert MDD_EPSS[0] > 0\n",
    "\n",
    "#     rcr_dict = defaultdict(list)\n",
    "#     rcr_dict['gamma'].extend(gammas)\n",
    "#     ar_dict = defaultdict(list)\n",
    "#     ar_dict['gamma'].extend(gammas)\n",
    "#     counts_dict = defaultdict(list)\n",
    "#     counts_dict['gamma'].extend(gammas)\n",
    "#     exp_list = []\n",
    "\n",
    "#     res = rcm_dfs[cfg_names[0]]\n",
    "#     rcr_real = res.real_rev.sum() / res.pub_rev.sum() * 100\n",
    "#     rcr_dict['Real'].extend([rcr_real]*len(gammas))\n",
    "#     ar_real = res.accepted.mean()*100\n",
    "#     ar_dict['Real'].extend([ar_real]*len(gammas))\n",
    "\n",
    "#     for cfgn in cfg_names:\n",
    "#         res = rcm_dfs[cfgn]\n",
    "\n",
    "#         for gamma in gammas:\n",
    "#             close = res[(res.real_discount >= res[f'rom_discount_{gamma}_low']-0.2) & (res.real_discount <= res[f'rom_discount_{gamma}_high']+0.2)]\n",
    "#             rcr_rom = close.real_rev.sum() / close.pub_rev.sum() * 100\n",
    "#             rcr_dict[cfgn].append(rcr_rom)\n",
    "#             counts_dict[cfgn].append(len(close))\n",
    "#             ar_dict[cfgn].append(close.accepted.mean()*100)\n",
    "\n",
    "#             rcr_exp = close.rom_exp_rev.sum() / close.pub_rev.sum() * 100\n",
    "#             exp_list.append(pd.Series(dict(name=cfgn, gamma=gamma, rcr=rcr_rom, calc='real')))\n",
    "#             exp_list.append(pd.Series(dict(name=cfgn, gamma=gamma, rcr=rcr_exp, calc='predicted')))\n",
    "\n",
    "#     m = 'mdd'\n",
    "#     for eps in MDD_EPSS:\n",
    "#         close = res[np.abs(res[f'{m}_diff']) < eps]\n",
    "#         rcr_mdd = close.real_rev.sum() / close.pub_rev.sum() * 100\n",
    "#         rcr_dict['MDD'].append(rcr_mdd)\n",
    "#         ar_dict['MDD'].append(close.accepted.mean()*100)\n",
    "#         counts_dict['MDD'].append(len(close))\n",
    "\n",
    "#         # rcr_dict['Real'].append(rcr_real)\n",
    "\n",
    "#     # rcr_mdd = close.real_rev.sum() / close.pub_rev.sum() * 100\n",
    "\n",
    "#     rcr_df = pd.DataFrame(rcr_dict).set_index('gamma')\n",
    "#     counts_df = pd.DataFrame(counts_dict).set_index('gamma')\n",
    "#     ar_df = pd.DataFrame(ar_dict).set_index('gamma')\n",
    "#     exp_df = pd.DataFrame(exp_list)\n",
    "\n",
    "#     # print(f'Acceptance rate: {res.accepted.mean()*100:.0f}%')\n",
    "\n",
    "#     return rcr_df, counts_df, ar_df, rcr_real, ar_real, exp_df\n",
    "\n",
    "\n",
    "def plot_rcr_comparison(\n",
    "    rcr_df,\n",
    "    counts_df,\n",
    "    ar_df,\n",
    "    rcr_real,\n",
    "    ar_real,\n",
    "    ar,\n",
    "    save_figures,\n",
    "    check_issues=True,\n",
    "    subset=None,\n",
    "):\n",
    "    global \\\n",
    "        ctr_name, \\\n",
    "        exp_name, \\\n",
    "        cfg_names, \\\n",
    "        cfg_hash, \\\n",
    "        clf_dfs, \\\n",
    "        rcm_dfs, \\\n",
    "        eval_dfs, \\\n",
    "        MDD_EPSS, \\\n",
    "        n_samples\n",
    "\n",
    "    if subset:\n",
    "        rcr_df = rcr_df[[\"Real\"] + subset + [\"MDD\"]]\n",
    "        ar_df = ar_df[[\"Real\"] + subset + [\"MDD\"]]\n",
    "        counts_df = counts_df[subset + [\"MDD\"]]\n",
    "\n",
    "    if check_issues:\n",
    "        below_rcr = rcr_df.drop(columns=[\"Real\", \"MDD\"]).mean() < rcr_real\n",
    "        below_rcr = below_rcr[below_rcr].index.to_list()\n",
    "        if len(below_rcr) > 0:\n",
    "            raise_warning(\"ROM's RCR drops below real RCR!\", 50, below_rcr)\n",
    "\n",
    "        below_counts = (counts_df.drop(columns=\"MDD\") / n_samples * 100 < 10).loc[\n",
    "            gammas[1]\n",
    "        ]\n",
    "        below_counts = below_counts[below_counts].index.to_list()\n",
    "        if len(below_counts) > 0:\n",
    "            raise_warning(\"Subset(s) smaller than 10%!\", 30, below_counts)\n",
    "\n",
    "    xticks = [f\"{g} ({e})\" for g, e in zip(gammas, MDD_EPSS)]\n",
    "    markers = get_markers(n_configs)\n",
    "\n",
    "    width = 15 if ar else 10\n",
    "    n_cols_ = 3 if ar else 2\n",
    "    fig = plt.figure(figsize=(width, 10))\n",
    "    gs = fig.add_gridspec(2, n_cols_, height_ratios=[2, 3])\n",
    "    ax1 = fig.add_subplot(gs[0, :])\n",
    "    ax2 = fig.add_subplot(gs[1, 0])\n",
    "    ax3 = fig.add_subplot(gs[1, 1])\n",
    "    if ar:\n",
    "        ax4 = fig.add_subplot(gs[1, 2])\n",
    "\n",
    "    # plot RCR\n",
    "    ax = rcr_df.plot(ax=ax2)\n",
    "    ax.set_title(\"RCR\")\n",
    "    ax.set_xlabel(\"Γ (ε)\")\n",
    "    ax.yaxis.set_major_formatter(PercentFormatter(decimals=0))\n",
    "    # ax.set_ylim((0, None))\n",
    "    ax.set_xticks(gammas, xticks)\n",
    "\n",
    "    lines = ax.get_lines()\n",
    "    real_line = lines[0]\n",
    "    real_line.set_c(\"hotpink\")\n",
    "    real_line.set_ls(\"--\")\n",
    "\n",
    "    for m, line in zip(markers, lines):\n",
    "        line.set_marker(m)\n",
    "    mdd_line = lines[-1]\n",
    "    mdd_line.set_c(\"grey\")\n",
    "    mdd_line.set_ls(\"--\")\n",
    "\n",
    "    if ar:\n",
    "        ax.legend([])\n",
    "    else:\n",
    "        ax.legend(bbox_to_anchor=(1.04, 1))\n",
    "\n",
    "    colors = [l.get_c() for l in ax.get_lines()]\n",
    "\n",
    "    # plot counts\n",
    "    # todo swap % with counts\n",
    "    ax = counts_df.plot.line(marker=\"o\", ax=ax3)\n",
    "    ax.set_title(f\"num offers in subset (total: {n_samples})\")\n",
    "    ax.set_xlabel(\"Γ (ε)\")\n",
    "\n",
    "    for l, c, m in zip(ax.get_lines(), colors[1:], markers[1:]):\n",
    "        l.set_c(c)\n",
    "        l.set_marker(m)\n",
    "    mdd_line = ax.get_lines()[-1]\n",
    "    mdd_line.set_ls(\"--\")\n",
    "\n",
    "    # ax.set_ylim((0, None))\n",
    "    ax.legend([])\n",
    "    ax.set_xticks(gammas, xticks)\n",
    "    yticks = ax.get_yticks()\n",
    "    ax.set_yticks(yticks, [f\"{int(y)} ({y / n_samples * 100:.1f}%)\" for y in yticks])\n",
    "\n",
    "    if ar:\n",
    "        # plot acceptance rate\n",
    "        ax = ar_df.plot(ax=ax4)\n",
    "        ax.set_title(\"Acceptance Rate\")\n",
    "        ax.set_xlabel(\"Γ (ε)\")\n",
    "        ax.yaxis.set_major_formatter(PercentFormatter(decimals=0))\n",
    "        # ax.set_ylim((0, None))\n",
    "        ax.set_xticks(gammas, xticks)\n",
    "\n",
    "        lines = ax.get_lines()\n",
    "        real_line = lines[0]\n",
    "        real_line.set_c(\"hotpink\")\n",
    "        real_line.set_ls(\"--\")\n",
    "\n",
    "        for m, line in zip(markers, lines):\n",
    "            line.set_marker(m)\n",
    "        mdd_line = lines[-1]\n",
    "        mdd_line.set_c(\"grey\")\n",
    "        mdd_line.set_ls(\"--\")\n",
    "        ax.legend(bbox_to_anchor=(1.04, 1))\n",
    "\n",
    "    # plot avg rcr\n",
    "    ax = rcr_df.mean().round(1).plot.bar(rot=15, color=colors, ax=ax1)\n",
    "    ax.yaxis.set_major_formatter(PercentFormatter(decimals=0))\n",
    "    ax.bar_label(ax.containers[0])\n",
    "    ax.set_title(\"Avg RCR\")\n",
    "    ax.axhline(rcr_real, c=\"grey\", ls=\":\")\n",
    "\n",
    "    subset_title_sfx = f\" - {len(subset)}/{len(cfg_names)} configs\" if subset else \"\"\n",
    "    plt.suptitle(f\"{ctr_name} - exp. {exp_name}{subset_title_sfx}\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    warn_suffix = (\n",
    "        f\"_W{round(warning_score) if warning_score >= 1 else round(warning_score, 1)}\"\n",
    "        if warning_score\n",
    "        else \"\"\n",
    "    )\n",
    "    subset_suffix = \"_sub\" if subset else \"\"\n",
    "    if save_figures:\n",
    "        dir_path = f\"{ROM_PLOT_DIR}/experiment-rcr/per_exp/{exp_name}\"\n",
    "        fig_path = f\"{dir_path}/{ctr_name}_{cfg_hash}{warn_suffix}{subset_suffix}.png\"\n",
    "        Path(dir_path).mkdir(parents=True, exist_ok=True)\n",
    "        plt.savefig(fig_path)\n",
    "\n",
    "        dir_path2 = f\"{ROM_PLOT_DIR}/experiment-rcr/per_ctr/{ctr_name}\"\n",
    "        fig_path2 = f\"{dir_path2}/{exp_name}_{cfg_hash}{warn_suffix}{subset_suffix}.png\"\n",
    "        Path(dir_path2).mkdir(parents=True, exist_ok=True)\n",
    "        plt.savefig(fig_path2)\n",
    "        print(f\"Saved figure to:\\n{fig_path}\\n{fig_path2}\")\n",
    "\n",
    "\n",
    "def corr_logloss_rcr(metrics, rcr_df, negative=False):\n",
    "    metrics = metrics.copy()\n",
    "    metrics[\"rcr\"] = rcr_df.drop(columns=[\"Real\", \"MDD\"]).mean()\n",
    "    metrics[\"negative_logloss\"] = -metrics[\"logloss\"]\n",
    "    x = \"logloss\" if not negative else \"negative_logloss\"\n",
    "    sns.regplot(metrics, x=x, y=\"rcr\")\n",
    "\n",
    "\n",
    "### Select best config\n",
    "\n",
    "\n",
    "def calc_within_score(within):\n",
    "    # thresh = 25\n",
    "    # thresh2 = 10\n",
    "    # return -(thresh - np.minimum(thresh, within))**(1.4) - (thresh2 - np.minimum(thresh2, within))**(1.8)\n",
    "    thresh = 27\n",
    "    thresh2 = 12\n",
    "    thresh3 = 40\n",
    "    return (\n",
    "        -((thresh - np.minimum(thresh, within)) ** (1.2))\n",
    "        - (thresh2 - np.minimum(thresh2, within)) ** (1.7)\n",
    "        - (thresh3 - np.minimum(thresh3, within)) ** (0.8)\n",
    "    )\n",
    "\n",
    "\n",
    "def select_best_cfg(rcr_df, counts_df, subset):\n",
    "    global n_samples\n",
    "    rcr = rcr_df[subset]\n",
    "    counts = counts_df[subset]\n",
    "    rcr_max = rcr.mean().max()\n",
    "    rcr_real = rcr_df.Real.iloc[0]\n",
    "    rcr_score = (rcr.mean() - rcr_real) / (rcr_max - rcr_real) * 100\n",
    "\n",
    "    within = counts.mean() / n_samples * 100\n",
    "    within_score = calc_within_score(within)\n",
    "\n",
    "    score = rcr_score + within_score\n",
    "    display(\n",
    "        pd.DataFrame(\n",
    "            dict(rcr_score=rcr_score, within_score=within_score, score=score)\n",
    "        ).round(1)\n",
    "    )\n",
    "    score_sorted = score.sort_values(ascending=False)\n",
    "    cfg_best = score_sorted.index[0]\n",
    "    return cfg_best\n",
    "\n",
    "\n",
    "def select_best_gamma(rcr_df, counts_df, cfgn):\n",
    "    global n_samples\n",
    "    rcr = rcr_df[cfg_best]\n",
    "    counts = counts_df[cfg_best]\n",
    "\n",
    "    rcr_max = rcr.max()\n",
    "    rcr_real = rcr_df.Real.iloc[0]\n",
    "    rcr_score = (rcr - rcr_real) / (rcr_max - rcr_real) * 100\n",
    "\n",
    "    within = counts / n_samples * 100\n",
    "\n",
    "    within_score = calc_within_score(within)\n",
    "\n",
    "    score = rcr_score + within_score\n",
    "    display(\n",
    "        pd.DataFrame(\n",
    "            dict(rcr_score=rcr_score, within_score=within_score, score=score)\n",
    "        ).round(1)\n",
    "    )\n",
    "    score_sorted = score.sort_values(ascending=False)\n",
    "    return score_sorted.index[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f472f4-9da2-4a85-99b9-250347e2c13d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Select country and experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e233c8f9-57bd-4e17-8594-51eb3d7f30d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exp2ctrs = show_experiments_w_countries(name_pattern=\"v07\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23a789c-65e9-4109-9711-5df1cd0a4af3",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\"><b>You may preselect an experiment</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6992c239-02be-4574-bc0e-3d56d035daf3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preselected_exp = \"v02-trn-period\"\n",
    "preselected_exp = \"v02-CH-trnm3\"\n",
    "# preselected_exp = 'augm-basic-ab-02-fixed'\n",
    "preselected_exp = \"v02-different-trn-periods\"\n",
    "# preselected_exp = 'augm-weight-01'\n",
    "preselected_exp = \"v03-onboarding\"\n",
    "preselected_exp = \"v05-onboarding-test\"\n",
    "preselected_exp = \"v06-2025-onboarding\"\n",
    "preselected_exp = \"v07-mck-poc\"\n",
    "# preselected_exp = None\n",
    "\n",
    "# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "ctr_spans, ctr_paths = show_available_countries(preselected_exp, exp2ctrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af515d47-6374-4b51-9bc8-057e0c213b5e",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\"><b>Select country</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7cbf9a-1f47-43e0-bb1a-ee5125bf5d27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "country_selection = 0\n",
    "\n",
    "# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "ctr_name, span, exp_paths, exp_names, preselected_exp_idx = show_available_experiments(\n",
    "    country_selection, ctr_spans, ctr_paths, preselected_exp\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2eb073-45ed-4a84-a550-70e55302791d",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\"><b>Select experiment</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5373f5cc-aab5-4c5e-b09e-d6ba9a2e02f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "experiment_selection = 0\n",
    "# preselected_exp_idx = None\n",
    "\n",
    "# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "exp_name, cfg_paths, cfg_names_all = show_available_configs(\n",
    "    experiment_selection, preselected_exp_idx, exp_names\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51c5379-a5ef-42dd-90f7-56b803cd27e5",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\"><b>Select configurations</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df7acd9-3c27-4d38-9097-337cf9415e21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# config_selection = 4,5,11,12,14,15,16,17,20,21\n",
    "# config_selection = 0,1,6,7,9,10,11,12,13\n",
    "# config_selection = 5,12,15,17,21\n",
    "# config_selection = 0,1,6,7\n",
    "config_selection = None\n",
    "\n",
    "# temp\n",
    "# config_selection = 0,1,5,6,7,10,11,15,16,4,19\n",
    "\n",
    "# all cm1\n",
    "# config_selection = list(map(lambda x: x[0], filter(lambda x: 'cm1' in x[1], list(enumerate(cfg_names_all)))))\n",
    "\n",
    "# weight 0.4\n",
    "# config_selection = list(map(lambda x: x[0], filter(lambda x: 'cm1' not in x[1] and '0.4' in x[1], list(enumerate(cfg_names_all)))))\n",
    "\n",
    "\n",
    "# config_selection = list(map(lambda x: x[0], filter(lambda x: any(s in x[1] for s in '0.4 0.6 1.0'.split()), list(enumerate(cfg_names_all)))))\n",
    "\n",
    "# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "cfg_names, cfg_hash, config_selection = show_selected_configs(\n",
    "    config_selection, cfg_names_all\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb13220-35a6-4615-8f6f-55ab62746f5e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load data and prep evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e1f62a-509e-475f-8c5e-900341e4b0e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(\n",
    "    clf_dfs,\n",
    "    rcm_dfs,\n",
    "    eval_dfs,\n",
    "    n_samples,\n",
    "    configs,\n",
    "    (n_cols, n_rows, n_cols_wide, n_rows_wide),\n",
    "    models,\n",
    "    n_models,\n",
    "    gammas,\n",
    "    n_configs,\n",
    ") = load_data_and_prep_eval(config_selection, cfg_paths, n_cols=4, n_cols_wide=2)\n",
    "# rcr_df, counts_df, ar_df, rcr_real, ar_real, exp_df = calc_rcr_dfs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc52fec-9bd4-4d15-833f-7524bdc6f114",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9a37bab-c1c0-4775-81ee-dd62c04e7a9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# show_selected_evaluation(ctr_name, span, exp_name, cfg_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6d416e-37a3-4857-9bdf-360cc3082d8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "list(rcm_dfs.values())[0].accepted.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085582c4-3bdc-42c4-b9bf-7e7d3baaa980",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128d918b-e4bb-45da-8b54-c0b7ad0017aa",
   "metadata": {
    "tags": []
   },
   "source": [
    "### ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8fa463-6243-47d1-a311-68529d161665",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_roc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c3ee39-ccb4-4d08-85c4-c37eee0c9dd0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Recommended discounts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228f88f7-529d-4a15-9442-a330315dcfe3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Distribution of discounts\n",
    "\n",
    "- red X - 0% recommended discounts more frequent than 0% real discounts\n",
    "- blue X - medians of discounts differ too much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1090733f-5e78-4020-b903-c9038ef8ade8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ax = plot_discount_distributions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0222cd7d-b196-48c5-b939-d65e5ada7875",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Difference between real and recommended discounts\n",
    "\n",
    "- red X - Much smaller recommended discounts than real discounts\n",
    "- blue X - Unexpected median value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f556e0-cd82-46ef-95ff-572e5f4934cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_difference_between_discounts(show_means=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b914e056-54fb-462b-904c-653758447974",
   "metadata": {
    "tags": []
   },
   "source": [
    "## RCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ae607563-ddb0-48fe-97af-1a05951cb948",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot_rcr_comparison(rcr_df, counts_df, ar_df, rcr_real, ar_real, ar=True, save_figures=True, check_issues=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69dc9f6c-7e5d-4889-95a6-4b307a29c2c2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### ε-RCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c7f452-5576-4f8b-89b0-7c46d3b3c442",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# todo improve this code, maybe add to trainer\n",
    "epsilons = [0.2, 0.5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 14, 16]\n",
    "eps_dict = defaultdict(list)\n",
    "eps_dict[\"eps\"] = epsilons\n",
    "\n",
    "res = rcm_dfs[models[0]]\n",
    "# res = res[res.pub_rev < res.pub_rev.quantile(0.95)]\n",
    "rev0 = res.real_rev.mean()\n",
    "acc0 = res.accepted.mean()\n",
    "rcr0 = res.real_rev.sum() / res.pub_rev.sum() * 100\n",
    "\n",
    "arcr0 = (res.real_rev / res.pub_rev).mean() * 100\n",
    "\n",
    "close_dict = {}\n",
    "\n",
    "for EPS in epsilons:\n",
    "    for m in models:\n",
    "        m_ = \"rom\"\n",
    "        res = rcm_dfs[m] if m != \"MDD\" else rcm_dfs[models[0]]\n",
    "\n",
    "        close = res[np.abs(res[f\"{m_}_diff\"]) < EPS + 0.2]\n",
    "        if m_ == \"rom\":\n",
    "            close_dict[EPS] = close\n",
    "\n",
    "        acc1 = close.accepted.mean()\n",
    "        rcr1 = close.real_rev.sum() / close.pub_rev.sum() * 100\n",
    "        arcr1 = (close.real_rev / close.pub_rev).mean() * 100\n",
    "        rcr_inc1 = rcr1 / rcr0 * 100 - 100\n",
    "\n",
    "        eps_dict[f\"{m}_rcr_increase\"].append(rcr_inc1)\n",
    "        eps_dict[f\"{m}_rcr\"].append(rcr1)\n",
    "        eps_dict[f\"{m}_arcr\"].append(arcr1)\n",
    "        eps_dict[f\"{m}_acc_rate\"].append(acc1)\n",
    "        eps_dict[f\"{m}_counts\"].append(len(close))\n",
    "\n",
    "eps_df = pd.DataFrame(eps_dict).set_index(\"eps\")\n",
    "eps_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f842d45-eaf1-4213-a714-9e779b91305e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 7))\n",
    "\n",
    "gs = fig.add_gridspec(2, 2, width_ratios=[2, 1])\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "ax2 = fig.add_subplot(gs[1, 0])\n",
    "ax3 = fig.add_subplot(gs[:, 1])\n",
    "\n",
    "# fig, axes = plt.subplots(2, 2, )\n",
    "# axes = axes.flatten()\n",
    "\n",
    "ax = eps_df[[f\"{m}_rcr\" for m in models]].plot(marker=\"o\", ax=ax1)\n",
    "ax.axhline(rcr0, c=\"r\", ls=\"--\")\n",
    "ax.set_title(\"RCR comparison\")\n",
    "ax.xaxis.set_minor_locator(MultipleLocator(1))\n",
    "ax.tick_params(which=\"both\", bottom=True)\n",
    "# ax.legend(model_names)\n",
    "ax.set_xlabel(\"ε\")\n",
    "ax.yaxis.set_major_formatter(PercentFormatter(decimals=0))\n",
    "\n",
    "\n",
    "ax = eps_df[[f\"{m}_acc_rate\" for m in models]].plot(marker=\"o\", ax=ax2)\n",
    "ax.axhline(acc0, c=\"r\", ls=\"--\")\n",
    "ax.set_title(\"Acceptance rate\")\n",
    "ax.yaxis.set_major_formatter(PercentFormatter(xmax=1, decimals=0))\n",
    "ax.xaxis.set_minor_locator(MultipleLocator(1))\n",
    "ax.tick_params(which=\"both\", bottom=True)\n",
    "# ax.legend(model_names)\n",
    "ax.set_xlabel(\"ε\")\n",
    "\n",
    "df = eps_df[[f\"{m}_counts\" for m in models]]\n",
    "ax = df.plot.bar(ax=ax3)\n",
    "tick_step = calc_tick_step(df.max().max() * 1.05)\n",
    "ax.yaxis.set_major_locator(MultipleLocator(tick_step))\n",
    "ax.yaxis.set_major_formatter(\"{x:,.0f}\")\n",
    "ax.yaxis.set_minor_locator(MultipleLocator(tick_step // 5))\n",
    "ax.tick_params(which=\"both\", left=True)\n",
    "ax.set_title(\"Number of offers included\")\n",
    "ax.set_ylabel(\"Number of offers\")\n",
    "# ax.legend(model_names)\n",
    "ax.set_xlabel(\"ε\")\n",
    "\n",
    "plt.suptitle(f\"{ctr_name} - ε-RCR\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2d06eb-c3c0-4b6d-9a45-80c07284af93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 7))\n",
    "\n",
    "ax = eps_df[[f\"{m}_rcr\" for m in models]].plot(marker=\"o\", ax=ax, lw=2)\n",
    "ax.axhline(rcr0, c=\"r\", ls=\"--\")\n",
    "ax.set_title(\"RCR comparison\")\n",
    "ax.xaxis.set_minor_locator(MultipleLocator(1))\n",
    "ax.tick_params(which=\"both\", bottom=True)\n",
    "# ax.legend(model_names)\n",
    "ax.set_xlabel(\"ε\")\n",
    "ax.yaxis.set_major_formatter(PercentFormatter(decimals=0))\n",
    "\n",
    "plt.suptitle(f\"{ctr_name} - ε-RCR\")\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
